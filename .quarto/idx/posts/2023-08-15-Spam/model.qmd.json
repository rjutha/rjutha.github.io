{"title":"A Simple brms Model for predicting spam emails","markdown":{"yaml":{"title":"A Simple brms Model for predicting spam emails","format":{"html":{"code-fold":true,"code-summary":"Show code"}},"server":"shiny"},"headingText":"Introduction","containsRefs":false,"markdown":"\n\n\nThe point of making this document was to try out using quarto as an alternative to the standard rmarkdown file. I was also curious about the Rshiny integration that quarto has so I used the Tidy Tuesday data from 2023-08-15 to create an example. \n\n## Load Libraries\n\nThe R packages that I'll be using are tidyverse, janitor, and brms. The tidyverse will be used for general data manipulation as well as the stringr functions for string detection. Janitor is just for the clean_names function which is a game changer. Lastly the brms package is going to be used for a Bayesian Regression Model. Note that shiny does not need to be called for the integration with quarto to work.\n\n```{r}\n#| echo: true\n#| eval: false  \nlibrary(tidyverse)\nlibrary(janitor)\nlibrary(brms)\n```\n\n## Load Data\n\nThe data is loaded straight from the tidy tuesday repository. The data is a subset of the original data which can be found [here]{https://archive.ics.uci.edu/dataset/94/spambase}. This subset contains 4601 records and only a handful of the full set of variables to model against.\n\n```{r}\n#| echo: true\n#| eval: false\nraw_data <- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2023/2023-08-15/spam.csv') %>%\n  clean_names()\n```\n\n## Run Model\n\nHere the data is transformed before creating the model. When the model is finished I save it to speed up the shinyapp so it doesn't have to build the model on start up.\n```{r}\n#| echo: true\n#| eval: false\nmod_data <- raw_data %>%\n  mutate(\n    yesno = case_when(\n      yesno == 'y' ~ 1,\n      yesno == 'n' ~ 0,\n    )\n  )\n\nmod <- brm(yesno ~ ., data = mod_data)\nsummary(mod)\n\nsaveRDS(mod, \"model.rds\")\n```\n\n## Spam Detection App\n\nNote that since I am only using a small subset of the data, the prediction are not the most reliable and I do not recommend basing any decisions on these results. The main purpose of this app was to create an interesting quarto document.\n\n```{r}\n#| echo: true\ntextAreaInput(\n  \"spam_text\",\n  markdown(\"**Input text to be used by the model**\"), \n  value = 'thank you for your purchase through NORTON. this email that is to inform you your annual subscription with Norton is RENEWED.\nHere is an overview of your recent purchase :-\nPRODUCT INFO\ninvoice no:- NYR7755269R\nORDER date :- 09/09/2021\nPAYMENT method: - auto - debited\nVALUE :- $321.67\nto upgrade /cancel your subscription, PLEASE contact our customer service at\n+1 (810)-(515)-(7954)\nThank you,\nNorton billing support',\n  width = '100%',\n  rows = 6,\n  placeholder = 'Enter some text')\n\nplotOutput(\"posterior_prediction_plot\")\n```\n\n```{r}\n#| echo: true\n#| context: server\nlibrary(tidyverse)\nlibrary(brms)\nmod <- read_rds('./model.rds')\n\nupdate_spam <- reactive({\n  spam_text <- input$spam_text\n  n_char <- str_length(spam_text)\n  n_word <- str_count(spam_text, '[\\\\d\\\\w]+')\n  crl_tot <- str_count(spam_text, '[A-Z]')\n  dollar <- str_count(spam_text, '\\\\$') / n_char * 100\n  bang <- str_count(spam_text, '!') / n_char * 100\n  money <- str_count(str_to_lower(spam_text), 'money') / n_word * 100\n  n000 <- str_count(spam_text, '000') / n_word * 100\n  make <- str_count(str_to_lower(spam_text), 'make') / n_word * 100\n  \n  df_new_spam <- tibble(\n    dollar = dollar, bang = bang, money = money,\n    n000 = n000, make = make, crl_tot = crl_tot)\n\n  pred <- posterior_predict(mod, newdata = df_new_spam)[,1]\n  pred <- exp(pred)/(1+exp(pred))\n  return(pred)\n})\n\noutput$posterior_prediction_plot <- renderPlot({\n  pred <- update_spam()\n  pi_95 <- quantile(pred, probs = c(0.025, 0.975))\n  \n  ggplot() +\n    geom_histogram(aes(x =pred), bins = 150) +\n    scale_x_continuous(breaks = seq(0,1,0.25), limits = c(-0.05,1.05)) +\n    theme_minimal(\n      base_family = 'Source Sans Pro'\n    ) +\n    labs(\n      y = NULL,\n      x = 'Probability',\n      title = 'Posterior Prediction Interval for a new observation'\n    ) +\n    theme(\n      plot.title.position = 'plot',\n      plot.title = element_text(\n        size = 20,\n      ),\n      panel.grid =  element_blank(),\n      axis.text.y = element_blank()\n      \n    )\n})\n```\n\n##### Source code for the ShinyApp\n\n```{r}\n#| echo: true\n#| eval: false\nlibrary(tidyverse)\nlibrary(brms)\nmod <- read_rds('model.rds')\n\nupdate_spam <- reactive({\n  spam_text <- input$spam_text\n  n_char <- str_length(spam_text)\n  n_word <- str_count(spam_text, '[\\\\d\\\\w]+')\n  crl_tot <- str_count(spam_text, '[A-Z]')\n  dollar <- str_count(spam_text, '\\\\$') / n_char * 100\n  bang <- str_count(spam_text, '!') / n_char * 100\n  money <- str_count(str_to_lower(spam_text), 'money') / n_word * 100\n  n000 <- str_count(spam_text, '000') / n_word * 100\n  make <- str_count(str_to_lower(spam_text), 'make') / n_word * 100\n  \n  df_new_spam <- tibble(\n    dollar = dollar, bang = bang, money = money,\n    n000 = n000, make = make, crl_tot = crl_tot)\n\n  pred <- posterior_predict(mod, newdata = df_new_spam)[,1]\n  pred <- exp(pred)/(1+exp(pred))\n  return(pred)\n})\n\noutput$posterior_prediction_plot <- renderPlot({\n  pred <- update_spam()\n  pi_95 <- quantile(pred, probs = c(0.025, 0.975))\n  \n  ggplot() +\n    geom_histogram(aes(x =pred), bins = 150) +\n    scale_x_continuous(breaks = seq(0,1,0.25), limits = c(-0.05,1.05)) +\n    theme_minimal() +\n    labs(\n      y = NULL,\n      x = 'Probability',\n      title = 'Posterior Prediction Interval for a new observation'\n    ) +\n    theme(\n      plot.title.position = 'plot',\n      plot.title = element_text(\n        size = 25,\n      ),\n      panel.grid =  element_blank(),\n      axis.text.y = element_blank()\n      \n    )\n})\n```\n\nThe code above takes the users input and converts it into the variables that were used in the model. For example counting the amount of '!' are present in the text. It updates every time the text box is changed and plots a new Posterior Prediction Interval based on the results.\n"},"formats":{"html":{"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":true,"echo":false,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"engine":"knitr"},"render":{"keep-tex":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":true,"code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[]},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","css":["../../styles.css"],"toc":true,"toc-depth":3,"output-file":"model.html"},"language":{"code-summary":"Show code"},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.2.475","editor":"visual","theme":"cosmo","title-block-banner":true,"author":"Rahim Jutha","page-layout":"article","title":"A Simple brms Model for predicting spam emails","server":"shiny"},"extensions":{"book":{"multiFile":true}}}}}