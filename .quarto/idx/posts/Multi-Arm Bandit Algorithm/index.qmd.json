{"title":"How to enhance AB testing with the Multi-arm Bandit","markdown":{"yaml":{"title":"How to enhance AB testing with the Multi-arm Bandit","description":"An alternative algorithm for testing that allows for a more rapid decision than traditional apporaches.","bibliography":"resource.bib","twitter-card":{"image":"featured.png"},"author":[{"name":"Rahim Jutha","url":"https://rjutha.github.io/"}],"date":"09-05-2023","categories":["Data-Viz","R","TidyTuesday","Shiny","Bayesian"],"citation":{"url":"https://rjutha.github.io/posts/2023-08-15-Spam/"},"image":"featured.png","draft":false},"headingText":"Introduction","containsRefs":false,"markdown":"\n\nMessage to get across\n\"Multi-arm bandits offer an approach to testing, especially web testing, that allows explicit optimization and more rapid decision making than the traditional statistical approach to designing experiments \" [@psfds]\n\n\n\nCONTENTS\n\n\nintroduce post and what I'm writing about\n(an alternative to ab testing that is very applicable to web testing) providing an example for each approach along the way\n\n## AB testing\n\nIntroduce very briefly and provide a simple example.\nBe careful to not to spend too much time in this section since its not the main topic and focus.\n\n## Multi-Arm-Bandito\nintroduce algorithm formally\nwhy its better in web testing context\nsimple example (using the psilon-greedy algorithm for an A/B test described in teh text)\n\n##  Thompsonâ€™s sampling uses a Bayesian approach:\n\nsame concept using a beta prior instead seems better will read about it and provide a breif example\n\n"},"formats":{"html":{"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":true,"echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"engine":"markdown"},"render":{"keep-tex":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[]},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","css":["../../styles.css"],"toc":true,"toc-depth":3,"output-file":"index.html"},"language":{},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.2.475","editor":"visual","theme":"cosmo","title-block-banner":true,"page-layout":"article","title":"How to enhance AB testing with the Multi-arm Bandit","description":"An alternative algorithm for testing that allows for a more rapid decision than traditional apporaches.","bibliography":["resource.bib"],"twitter-card":{"image":"featured.png"},"author":[{"name":"Rahim Jutha","url":"https://rjutha.github.io/"}],"date":"09-05-2023","categories":["Data-Viz","R","TidyTuesday","Shiny","Bayesian"],"citation":{"url":"https://rjutha.github.io/posts/2023-08-15-Spam/"},"image":"featured.png","draft":false},"extensions":{"book":{"multiFile":true}}}}}